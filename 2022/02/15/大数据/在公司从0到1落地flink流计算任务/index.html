<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>【大数据】- 在公司从0到1落地flink流计算任务 | 白菜君の技术库</title>

  
  <meta name="author" content="白菜(whiteCcinn)">
  

  
  <meta name="description" content="知道做不到，等于不知道">
  

  
  <meta name="keywords" content="白菜,文辉,技术博客,whiteCcinn">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="【大数据】- 在公司从0到1落地flink流计算任务"/>

  <meta property="og:site_name" content="白菜君の技术库"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="白菜君の技术库" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 4.2.1"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">白菜君の技术库</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives/">文章</a></li>
      
        <li><a href="/tags/">标签</a></li>
      
        <li><a href="/categories/">分类</a></li>
      
        <li><a href="/about/">关于我</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>【大数据】- 在公司从0到1落地flink流计算任务</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2022/02/15/大数据/在公司从0到1落地flink流计算任务/" rel="bookmark">
        <time class="entry-date published" datetime="2022-02-15T03:10:40.000Z">
          2022-02-15
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在公司落地一套flink，总结到目前为止做了的事情。</p>
<a id="more"></a>

<h2 id="开发环境的部署"><a href="#开发环境的部署" class="headerlink" title="开发环境的部署"></a>开发环境的部署</h2><p>我们默认场景下，<code>flink</code>使用<code>hive-catalog</code>，所以<code>hive</code>安装在这里。</p>
<p>Hive使用<code>mysql</code>作为<code>外部数据存储</code>，所以这里使用<code>mysql</code></p>
<p>对于flink的开发，如果我想要一整套的本地的docker开发环境。</p>
<p>需要集成如下服务：</p>
<ul>
<li>hadoop</li>
<li>hive</li>
<li>flink</li>
<li>kafka</li>
<li>mysql</li>
</ul>
<p>所以做了一个<a href="https://github.com/whiteCcinn/flink-docker-compose" target="_blank" rel="noopener">flink-docker-compose</a></p>
<p>在该项目中，由于不是采用<code>CDH</code>来集成的，都是一个个源码包手动安装的。所以需要下载源码包。</p>
<p>目前的版本为：</p>
<ul>
<li>flink: 1.12.0_2.11</li>
<li>mysql: 5.6 （8.0-jdbc）</li>
<li>kafka: 2.12_2.11</li>
<li>maven: 3.6.3</li>
<li>jdk: 8/11 (默认jdk8)</li>
</ul>
<blockquote>
<p>本地环境的话，jdk需要自行处理好</p>
</blockquote>
<ul>
<li>hadoop: 3.1.1</li>
<li>hive: 3.1.0</li>
</ul>
<h3 id="一键下载源码包"><a href="#一键下载源码包" class="headerlink" title="一键下载源码包"></a>一键下载源码包</h3><p>为了方便方便大家下载，对应的镜像链接，也都集成在了<code>download.sh</code>中，如果需要利用<code>迅雷</code>等p2p加速下载软件，可以通过从中提取出来 <code>url</code> 进行下载。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./download.sh all</span><br></pre></td></tr></table></figure>

<h3 id="可设置的-env"><a href="#可设置的-env" class="headerlink" title="可设置的.env"></a>可设置的<code>.env</code></h3><p>利用<code>docker-compose</code>对 <code>.env</code>的支持，可以在当中设置<code>build image</code>的一些环境变量和参数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Hadoop</span></span><br><span class="line">HADOOP_VERSION=3.1.1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hive</span></span><br><span class="line">HIVE_VERSION=3.1.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Scala</span></span><br><span class="line">SCALA_VERSION=2.11</span><br><span class="line"><span class="meta">#</span><span class="bash"> Flink</span></span><br><span class="line">FLINK_VERSION=1.12.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Kafka</span></span><br><span class="line">KAFKA_VERSION=2.4.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper</span></span><br><span class="line">ZOOKEEPER_VERSION=3.5.6</span><br><span class="line"><span class="meta">#</span><span class="bash"> Mysql</span></span><br><span class="line">MYSQL_VERSION=5.6</span><br><span class="line">MYSQL_DATABASE=default</span><br><span class="line">MYSQL_PORT=3306</span><br><span class="line">MYSQL_ROOT_PASSWORD=lnhzjm/B4qrSc</span><br><span class="line">MYSQL_ENTRYPOINT_INITDB=./deploy/mysql/docker-entrypoint-initdb.d</span><br><span class="line">MYSQL_TIMEZONE=UTC</span><br></pre></td></tr></table></figure>

<h3 id="kafka的网络"><a href="#kafka的网络" class="headerlink" title="kafka的网络"></a>kafka的网络</h3><p>我们知道kafka的网络协议是<code>支持多端口</code>的，由于我们有时候flink是在本地，有时候是在容器中，所以我们希望我们的kafka集群，支持容器内的网络，也支持和我们物理机的网络。</p>
<p>这个时候，我们需要设置kafka的2套端口协议。所以你可以看到</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kafka1:</span></span><br><span class="line">   <span class="attr">build:</span></span><br><span class="line">     <span class="attr">context:</span> <span class="string">./deploy/kafka</span></span><br><span class="line">     <span class="attr">args:</span></span><br><span class="line">       <span class="attr">scala_version:</span> <span class="string">$&#123;SCALA_VERSION&#125;</span></span><br><span class="line">       <span class="attr">kafka_version:</span> <span class="string">$&#123;KAFKA_VERSION&#125;</span></span><br><span class="line">   <span class="attr">container_name:</span> <span class="string">flink-kafka1</span></span><br><span class="line">   <span class="attr">ports:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'19092:19092'</span></span><br><span class="line">   <span class="attr">environment:</span></span><br><span class="line">     <span class="attr">KAFKA_PORT:</span> <span class="number">19092</span></span><br><span class="line">     <span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://kafka1:19092</span></span><br><span class="line">     <span class="attr">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:</span> <span class="string">PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT</span></span><br><span class="line">     <span class="attr">KAFKA_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://:19092</span></span><br><span class="line">     <span class="attr">KAFKA_ZOOKEEPER_CONNECT:</span> <span class="string">zookeeper:2181</span></span><br><span class="line">     <span class="attr">KAFKA_DEFAULT_REPLICATION_FACTOR:</span> <span class="number">3</span></span><br><span class="line">   <span class="attr">networks:</span></span><br><span class="line">     <span class="attr">flink-networks:</span></span><br><span class="line">       <span class="attr">ipv4_address:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.211</span></span><br><span class="line">   <span class="attr">extra_hosts:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'zookeeper:192.168.6.215'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka1:192.168.6.211'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka2:192.168.6.212'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka3:192.168.6.213'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka4:192.168.6.214'</span></span><br><span class="line">   <span class="attr">depends_on:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">zookeeper</span></span><br></pre></td></tr></table></figure>

<p>看到这里的</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://kafka1:19092</span></span><br><span class="line"><span class="attr">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:</span> <span class="string">PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT</span></span><br><span class="line"><span class="attr">KAFKA_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://:19092</span></span><br></pre></td></tr></table></figure>

<p>这个就是决定我们的<code>2套协议</code>的关键所在，分别是对<code>9092（容器内）</code>和<code>19092(和物理机)</code>端口的支持。</p>
<p>但是设置完了这个，由于一般kafka-client会从可本机的可访问的<code>dns服务器</code>上寻找<code>host映射</code>，在连接的时候必备的流程。</p>
<p>在本地连接的时候，会通过<code>kafka1/kafka2</code>等hostname返回到client，client需要在本机找到所有的ip映射，所以我们需要设置一下<code>etc/hosts</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "127.0.0.1 kafka1 kafka2 kafka3 kafka4" &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure>

<p>目前为止，我们所需要的环境变量已经处理完了。</p>
<h2 id="基于datastream-api的flink开发"><a href="#基于datastream-api的flink开发" class="headerlink" title="基于datastream-api的flink开发"></a>基于datastream-api的flink开发</h2><p>我们知道flink提供了3种API，分别是<code>datastream-api</code>,<code>table-api</code>,<code>sql-api</code></p>
<p><code>datastream</code>，也是flink的最原始的api，和flink集成一体，通过<code>datastream-api</code>，我们可以实现各种灵活的数据流处理。</p>
<p>按照我们以往对流计算数据的处理，在游戏公司中，一个游戏项目部署一个流计算的任务即为合理。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    └── main</span><br><span class="line">        ├── java</span><br><span class="line">        │   ├── deps</span><br><span class="line">        │   │   ├── oaYdSdk</span><br><span class="line">        │   │   │   ├── Youdu.java</span><br><span class="line">        │   │   │   └── test</span><br><span class="line">        │   │   │       └── YouduTest.java</span><br><span class="line">        │   │   └── util</span><br><span class="line">        │   │       ├── ParameterToolEnvironmentUtils.java</span><br><span class="line">        │   │       └── Util.java</span><br><span class="line">        │   └── org</span><br><span class="line">        │       └── cp</span><br><span class="line">        │           └── flink</span><br><span class="line">        │               ├── Bootstrap.java</span><br><span class="line">        │               ├── async</span><br><span class="line">        │               │   └── AsyncOaYdHttpClient.java</span><br><span class="line">        │               ├── events</span><br><span class="line">        │               │   ├── CommonEvent.java</span><br><span class="line">        │               │   ├── CommonEventHeader.java</span><br><span class="line">        │               │   ├── app_error</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_ban</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_client_loss</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_consume_gold</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_fcm_error</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_index_record</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_index_record_data</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_role_create</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   └── t_log_market</span><br><span class="line">        │               │       ├── Event.java</span><br><span class="line">        │               │       ├── EventHeader.java</span><br><span class="line">        │               │       └── EventLog.java</span><br><span class="line">        │               ├── jobs</span><br><span class="line">        │               │   ├── alarm</span><br><span class="line">        │               │   │   ├── ErrorReport_10008.java</span><br><span class="line">        │               │   │   ├── Job_10002.java</span><br><span class="line">        │               │   │   ├── Job_10008.java</span><br><span class="line">        │               │   │   ├── Job_19.java</span><br><span class="line">        │               │   │   ├── README.md</span><br><span class="line">        │               │   │   └── handler</span><br><span class="line">        │               │   │       ├── AbstractHandler.java</span><br><span class="line">        │               │   │       ├── errorReport_10008</span><br><span class="line">        │               │   │       │   ├── Logic.java</span><br><span class="line">        │               │   │       │   ├── Logic_10012.java</span><br><span class="line">        │               │   │       │   ├── Logic_19.java</span><br><span class="line">        │               │   │       │   └── Logic_20.java</span><br><span class="line">        │               │   │       ├── job_10002</span><br><span class="line">        │               │   │       │   ├── LogIndexRecordDataHandler.java</span><br><span class="line">        │               │   │       │   ├── LogIndexRecordHandler.java</span><br><span class="line">        │               │   │       │   └── model</span><br><span class="line">        │               │   │       │       ├── log_index_record</span><br><span class="line">        │               │   │       │       │   └── StatisticsMcfx2Model.java</span><br><span class="line">        │               │   │       │       └── log_index_record_data</span><br><span class="line">        │               │   │       │           └── StatisticsMcfx1Model.java</span><br><span class="line">        │               │   │       ├── job_10008</span><br><span class="line">        │               │   │       │   ├── AppErrorHandler.java</span><br><span class="line">        │               │   │       │   ├── LogFcmErrorHandler.java</span><br><span class="line">        │               │   │       │   └── model</span><br><span class="line">        │               │   │       │       ├── app_error</span><br><span class="line">        │               │   │       │       │   └── StatisticsAppErrorModel.java</span><br><span class="line">        │               │   │       │       └── log_fcm_error</span><br><span class="line">        │               │   │       │           └── StatisticsFcmErrorModel.java</span><br><span class="line">        │               │   │       └── job_19</span><br><span class="line">        │               │   │           ├── LogBanHandler.java</span><br><span class="line">        │               │   │           ├── LogClientLossHandler.java</span><br><span class="line">        │               │   │           ├── LogConsumeGoldHandler.java</span><br><span class="line">        │               │   │           ├── LogRoleCreateHandler.java</span><br><span class="line">        │               │   │           ├── TLogMarketHandler.java</span><br><span class="line">        │               │   │           └── model</span><br><span class="line">        │               │   │               ├── log_ban</span><br><span class="line">        │               │   │               │   └── StatisticsModel.java</span><br><span class="line">        │               │   │               ├── log_client_loss</span><br><span class="line">        │               │   │               │   └── IpMonitorModel.java</span><br><span class="line">        │               │   │               ├── log_consume_gold</span><br><span class="line">        │               │   │               │   ├── StatisticsBindGoldModel.java</span><br><span class="line">        │               │   │               │   └── StatisticsUnBindGoldModel.java</span><br><span class="line">        │               │   │               ├── log_role_create</span><br><span class="line">        │               │   │               │   └── SingleServerRoleCreateModel.java</span><br><span class="line">        │               │   │               └── t_log_market</span><br><span class="line">        │               │   │                   ├── MarketTransactionLogByBuyerModel.java</span><br><span class="line">        │               │   │                   └── MarketTransactionLogBySellerModel.java</span><br><span class="line">        │               │   └── stream</span><br><span class="line">        │               │       └── README.md</span><br><span class="line">        │               ├── mock</span><br><span class="line">        │               │   ├── MockAppError.java</span><br><span class="line">        │               │   ├── MockLogFcmError.java</span><br><span class="line">        │               │   └── README.md</span><br><span class="line">        │               ├── serializer</span><br><span class="line">        │               │   ├── AbstractSerializer.java</span><br><span class="line">        │               │   └── log_role_create</span><br><span class="line">        │               │       └── LogRoleCreateDeSerializer.java</span><br><span class="line">        │               └── sinks</span><br><span class="line">        │                   ├── AsyncOaYdSdkHttpSink.java</span><br><span class="line">        │                   ├── MysqlItem.java</span><br><span class="line">        │                   └── MysqlSink.java</span><br><span class="line">        └── resources</span><br><span class="line">            ├── application-dev.properties</span><br><span class="line">            ├── application-local.properties</span><br><span class="line">            ├── application-pro.properties</span><br><span class="line">            ├── application.properties</span><br><span class="line">            ├── jobs</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.ErrorReport_10008</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.Job_10002</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.Job_10008</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   └── org.cp.flink.jobs.alarm.Job_19</span><br><span class="line">            │       ├── application-dev.properties</span><br><span class="line">            │       ├── application-local.properties</span><br><span class="line">            │       ├── application-pro.properties</span><br><span class="line">            │       └── application.properties</span><br><span class="line">            └── log4j2.properties</span><br></pre></td></tr></table></figure>

<p>这是我们早期的一个<code>代码层级结构</code>，所有的流计算任务基于一个flink项目下，<code>resources</code>下的配置根据当前需要提交的项目和环境来进行区分加载具体的配置，可以做到支持<code>多环境</code>,<code>多项目</code>下配置灵活配置。</p>
<p>我们看到 <code>org.cp.flink</code>目下，就是我们的所有flink代码。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">➜  flinkjob git:(master) ✗ tree -d src/main/java/org</span><br><span class="line">src/main/java/org</span><br><span class="line">└── cp</span><br><span class="line">    └── flink</span><br><span class="line">        ├── async</span><br><span class="line">        ├── events</span><br><span class="line">        │   ├── app_error</span><br><span class="line">        │   ├── log_ban</span><br><span class="line">        │   ├── log_client_loss</span><br><span class="line">        │   ├── log_consume_gold</span><br><span class="line">        │   ├── log_fcm_error</span><br><span class="line">        │   ├── log_index_record</span><br><span class="line">        │   ├── log_index_record_data</span><br><span class="line">        │   ├── log_role_create</span><br><span class="line">        │   └── t_log_market</span><br><span class="line">        ├── jobs</span><br><span class="line">        │   ├── alarm</span><br><span class="line">        │   │   └── handler</span><br><span class="line">        │   │       ├── job_10002</span><br><span class="line">        │   │       │   └── model</span><br><span class="line">        │   │       │       ├── log_index_record</span><br><span class="line">        │   │       │       └── log_index_record_data</span><br><span class="line">        │   │       ├── job_10008</span><br><span class="line">        │   │       │   └── model</span><br><span class="line">        │   │       │       ├── app_error</span><br><span class="line">        │   │       │       └── log_fcm_error</span><br><span class="line">        │   │       └── job_19</span><br><span class="line">        │   │           └── model</span><br><span class="line">        │   │               ├── log_ban</span><br><span class="line">        │   │               ├── log_client_loss</span><br><span class="line">        │   │               ├── log_consume_gold</span><br><span class="line">        │   │               ├── log_role_create</span><br><span class="line">        │   │               └── t_log_market</span><br><span class="line">        │   └── stream</span><br><span class="line">        ├── mock</span><br><span class="line">        ├── serializer</span><br><span class="line">        │   └── log_role_create</span><br><span class="line">        └── sinks</span><br></pre></td></tr></table></figure>

<p>我们先看到，<code>jobs</code>目录下的，分为了2种类型，我们平时用的流计算任务可以分为2种，一种是常规的<code>告警属性</code>，另一种是<code>产品属性(类似BI系统需要的实时数据)</code>。</p>
<p>我们看到<code>alarm/handler/job_xxx</code>就是我们具体的项目。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">src/main/java/org/cp/flink/jobs/alarm/</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_10002.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_10008.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_19.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">README.md</span></span><br><span class="line"><span class="string">└──</span> <span class="string">handler</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">AbstractHandler.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">errorReport_10008</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic_10012.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic_19.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">Logic_20.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">job_10002</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogIndexRecordDataHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogIndexRecordHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">├──</span> <span class="string">log_index_record</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsMcfx2Model.java</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">└──</span> <span class="string">log_index_record_data</span></span><br><span class="line">    <span class="string">│</span>           <span class="string">└──</span> <span class="string">StatisticsMcfx1Model.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">job_10008</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">AppErrorHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogFcmErrorHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">├──</span> <span class="string">app_error</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsAppErrorModel.java</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">└──</span> <span class="string">log_fcm_error</span></span><br><span class="line">    <span class="string">│</span>           <span class="string">└──</span> <span class="string">StatisticsFcmErrorModel.java</span></span><br><span class="line">    <span class="string">└──</span> <span class="string">job_19</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogBanHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogClientLossHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogConsumeGoldHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogRoleCreateHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">TLogMarketHandler.java</span></span><br><span class="line">        <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_ban</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_client_loss</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">IpMonitorModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_consume_gold</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">├──</span> <span class="string">StatisticsBindGoldModel.java</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsUnBindGoldModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_role_create</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">SingleServerRoleCreateModel.java</span></span><br><span class="line">            <span class="string">└──</span> <span class="string">t_log_market</span></span><br><span class="line">                <span class="string">├──</span> <span class="string">MarketTransactionLogByBuyerModel.java</span></span><br><span class="line">                <span class="string">└──</span> <span class="string">MarketTransactionLogBySellerModel.java</span></span><br></pre></td></tr></table></figure>

<p>对于各个项目的<code>错误告警监控</code>，这里分为了多个<code>job</code>。</p>
<ul>
<li>Job_10002.java</li>
<li>Job_10008.java</li>
<li>Job_19.java</li>
</ul>
<p>我们从入口开始看</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> deps.util.Util;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.Bootstrap;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.AppErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.LogFcmErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.CommonEvent;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Job_10008</span> <span class="keyword">extends</span> <span class="title">Bootstrap</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(Job_10008<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = getStreamExecutionEnvironment(args, Job_10008<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>); <span class="comment">// checkpoint every 5000 msecs</span></span><br><span class="line"></span><br><span class="line">        ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">"bootstrap.servers"</span>, parameterTool.get(<span class="string">"kafka.source.bootstrap.servers"</span>));</span><br><span class="line">        props.setProperty(<span class="string">"group.id"</span>, parameterTool.get(<span class="string">"kafka.source.group"</span>));</span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, parameterTool.get(<span class="string">"kafka.source.enable.auto.commit"</span>));</span><br><span class="line">        props.put(<span class="string">"auto.commit.interval.ms"</span>, parameterTool.get(<span class="string">"kafka.source.auto.commit.interval.ms"</span>));</span><br><span class="line">        props.put(<span class="string">"session.timeout.ms"</span>, parameterTool.get(<span class="string">"kafka.source.session.timeout.ms"</span>));</span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置kafka并行度</span></span><br><span class="line">        env.setParallelism(parameterTool.getInt(<span class="string">"kafka.source.parallelism"</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        DataStream&lt;String&gt; stream = env</span><br><span class="line">                .addSource(<span class="keyword">new</span> FlinkKafkaConsumer&lt;&gt;(Arrays.asList(parameterTool.get(<span class="string">"kafka.source.topic"</span>).split(<span class="string">","</span>)), <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line">        env.setParallelism(parameterTool.getInt(<span class="string">"app.parallelism"</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;CommonEvent&gt; s0 = stream.filter((String json) -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                JSONObject.parseObject(json, CommonEvent<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                logger.error(json);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;).map(</span><br><span class="line">                (String json) -&gt; JSONObject.parseObject(json, CommonEvent<span class="class">.<span class="keyword">class</span>).<span class="title">setOriginJson</span>(<span class="title">json</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">CommonEvent</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;CommonEvent&gt; outputTagAppError = <span class="keyword">new</span> OutputTag&lt;CommonEvent&gt;(AppErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;CommonEvent&gt; outputTagLogFcmError = <span class="keyword">new</span> OutputTag&lt;CommonEvent&gt;(LogFcmErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 主流不需要了, 所以不需要调用collector.collect()</span></span><br><span class="line">        <span class="comment">// 2. 只要旁路输出流，因为要区分数据进行处理</span></span><br><span class="line">        <span class="comment">// 利用low-level-api的process算子处理旁路输出采集数据</span></span><br><span class="line">        SingleOutputStreamOperator&lt;CommonEvent&gt; s1 = s0.process(<span class="keyword">new</span> ProcessFunction&lt;CommonEvent, CommonEvent&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(CommonEvent event, Context context, Collector&lt;CommonEvent&gt; collector)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">switch</span> (event.getHeaders().getLogName()) &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"app_error"</span>:</span><br><span class="line">                        context.output(outputTagAppError, event);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"log_fcm_error"</span>:</span><br><span class="line">                        context.output(outputTagLogFcmError, event);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;CommonEvent&gt; AppErrorSource = s1.getSideOutput(outputTagAppError);</span><br><span class="line">        DataStream&lt;CommonEvent&gt; LogFcmErrorSource = s1.getSideOutput(outputTagLogFcmError);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Event&gt; AppErrorSource_s0 = AppErrorSource.map((CommonEvent event) -&gt; JSONObject.parseObject(event.getOriginJson(), Event<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">Event</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        DataStream&lt;org.cp.flink.events.log_fcm_error.Event&gt; LogFcmErrorSource_s0 = LogFcmErrorSource.map((CommonEvent event) -&gt; JSONObject.parseObject(event.getOriginJson(), org.cp.flink.events.log_fcm_error.Event<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">org</span>.<span class="title">cp</span>.<span class="title">flink</span>.<span class="title">events</span>.<span class="title">log_fcm_error</span>.<span class="title">Event</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        AppErrorHandler.build().handle(AppErrorSource_s0);</span><br><span class="line">        LogFcmErrorHandler.build().handle(LogFcmErrorSource_s0);</span><br><span class="line"></span><br><span class="line">        env.execute(Util.getCurrentJobName(((ParameterTool) env.getConfig().getGlobalJobParameters())));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于我们一个topic只能够可能存在多种数据，所以这里利用了<code>旁路由</code>进行了分流。把数据流分发到不同的<code>子流</code>中，我们再把<code>子流</code>传递不同的<code>Handler</code>进行处理。</p>
<p>这里例如: <code>AppErrorHandler</code>。我们以此为例子进行说明。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm.handler.job_10008;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.AbstractHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.model.app_error.StatisticsAppErrorModel;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppErrorHandler</span> <span class="keyword">extends</span> <span class="title">AbstractHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AppErrorHandler instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> AppErrorHandler <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> AppErrorHandler();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(DataStream&lt;Event&gt; s0)</span> </span>&#123;</span><br><span class="line">        ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 利用旁路输出多流到对应到model</span></span><br><span class="line">        <span class="comment">// StatisticsAppErrorModel</span></span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;Event&gt; outputTagStatisticsAppError = <span class="keyword">new</span> OutputTag&lt;Event&gt;(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Event&gt; s1 = s0.process(<span class="keyword">new</span> ProcessFunction&lt;Event, Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Event event, Context context, Collector&lt;Event&gt; collector)</span> </span>&#123;</span><br><span class="line">                context.output(outputTagStatisticsAppError, event);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Event&gt; sideOutputStreamAppError = s1.getSideOutput(outputTagStatisticsAppError);</span><br><span class="line"></span><br><span class="line">        StatisticsAppErrorModel.build().handle(sideOutputStreamAppError);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (parameterTool.getBoolean(<span class="string">"app.handler.print.console"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">            s0.print(AppErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于，我们希望到一条数据从<code>kafka</code>被<code>pull</code>下来到时候，可以用于多个不同的<code>流计算模型model</code>，所以我们在这里需要<code>copy</code>到多个<code>旁路输出</code>，但是这里我们只有一个<code>stream-model</code>，所以我们就只用一个来处理即可，从旁路输出拿到<code>datastream</code>之后，在对应的模型中进行<code>核心逻辑</code>处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm.handler.job_10008.model.app_error;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> deps.util.Util;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.KeySelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.WindowedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.windowing.WindowFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.TimeWindow;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.runtime.operators.util.AssignerWithPeriodicWatermarksAdapter;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.AbstractHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_19.model.log_ban.StatisticsModel;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.sinks.MysqlItem;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.sinks.MysqlSink;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 错误日志统计</span></span><br><span class="line"><span class="comment"> * 窗口：滚动事件窗口，每1分钟统计一次</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StatisticsAppErrorModel</span> <span class="keyword">extends</span> <span class="title">AbstractHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SINK_DATABASE = <span class="string">"db_app_log_alarm"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SINK_TABLE = <span class="string">"t_log_app_error_alarm_164"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> StatisticsAppErrorModel instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StatisticsAppErrorModel <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> StatisticsAppErrorModel();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(DataStream&lt;Event&gt; s0)</span> </span>&#123;</span><br><span class="line">        s0.getExecutionConfig().setAutoWatermarkInterval(<span class="number">5000L</span>);</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">"getAutoWatermarkInterval: &#123;&#125;"</span>, s0.getExecutionConfig().getAutoWatermarkInterval());</span><br><span class="line">        ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Event&gt; s1 = s0.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarksAdapter.Strategy&lt;&gt;(</span><br><span class="line">                        <span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.of(<span class="number">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="meta">@Override</span></span><br><span class="line">                            <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                                Long ts = event.getLogs().getMtime() * <span class="number">1000L</span>;</span><br><span class="line">                                logger.debug(</span><br><span class="line">                                        <span class="string">"thread-id: &#123;&#125;, eventTime: [&#123;&#125;|&#123;&#125;], watermark: [&#123;&#125;|&#123;&#125;]"</span>,</span><br><span class="line">                                        Thread.currentThread().getId(),</span><br><span class="line">                                        ts,</span><br><span class="line">                                        sdf.format(ts),</span><br><span class="line">                                        <span class="keyword">this</span>.getCurrentWatermark().getTimestamp(),</span><br><span class="line">                                        sdf.format(<span class="keyword">this</span>.getCurrentWatermark().getTimestamp())</span><br><span class="line">                                );</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">return</span> ts;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                )</span><br><span class="line">                        <span class="comment">// 尽可能和窗口大小保持一致，所以如果其中一个并行度出现问题的情况下</span></span><br><span class="line">                        <span class="comment">// 最大的延迟计算结果是一个窗口大小的时间</span></span><br><span class="line">                        .withIdleness(Duration.ofMinutes(<span class="number">1L</span>))</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        WindowedStream&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt; s2 = s1.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple5&lt;Integer, String, String, Integer, String&gt; <span class="title">getKey</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Tuple5.of(</span><br><span class="line">                        event.getLogs().getRelatedAppId(),</span><br><span class="line">                        event.getLogs().getChildApp(),</span><br><span class="line">                        event.getLogs().getSummary(),</span><br><span class="line">                        event.getLogs().getLevel(),</span><br><span class="line">                        event.getLogs().getIp()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">                .window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1L</span>)));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; s3 = s2.apply(<span class="keyword">new</span> WindowFunction&lt;Event, Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple5&lt;Integer, String, String, Integer, String&gt; key, TimeWindow timeWindow, Iterable&lt;Event&gt; iterable, Collector&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (Event event : iterable) &#123;</span><br><span class="line">                    sum++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.debug(<span class="string">"聚合窗口key: &#123;&#125;, 窗口中的数量:&#123;&#125;, 此时的窗口范围是[&#123;&#125;,&#123;&#125;)"</span>, key, sum, sdf.format(timeWindow.getStart()), sdf.format(timeWindow.getEnd()));</span><br><span class="line">                collector.collect(Tuple3.of(key, iterable.iterator().next(), sum));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        String sinkDatabase = parameterTool.get(StatisticsModel.class.getName() + ".sink_database", DEFAULT_SINK_DATABASE);</span><br><span class="line">        String sinkTable = parameterTool.get(StatisticsModel.class.getName() + ".sink_table", DEFAULT_SINK_TABLE);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;MysqlItem&gt; s4 = s3.map(e -&gt; &#123;</span><br><span class="line">                    HashMap&lt;String, Object&gt; kv = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                    kv.put(<span class="string">"related_app_id"</span>, e.f1.getLogs().getRelatedAppId());</span><br><span class="line">                    kv.put(<span class="string">"child_app"</span>, e.f1.getLogs().getChildApp());</span><br><span class="line">                    kv.put(<span class="string">"summary"</span>, e.f1.getLogs().getSummary());</span><br><span class="line">                    kv.put(<span class="string">"level"</span>, e.f1.getLogs().getLevel());</span><br><span class="line">                    kv.put(<span class="string">"ip"</span>, e.f1.getLogs().getIp());</span><br><span class="line"></span><br><span class="line">                    kv.put(<span class="string">"mtime"</span>, e.f1.getLogs().getMtime());</span><br><span class="line">                    kv.put(<span class="string">"mdate"</span>, Util.timeStamp2Date(Integer.toString(e.f1.getLogs().getMtime()), <span class="string">"yyyy-MM-dd"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 来自聚合窗口统计的结果</span></span><br><span class="line">                    kv.put(<span class="string">"cnt"</span>, e.f2);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> MysqlItem.builder()</span><br><span class="line">                            .database(sinkDatabase)</span><br><span class="line">                            .table(sinkTable)</span><br><span class="line">                            .kv(kv)</span><br><span class="line">                            .build();</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(MysqlItem<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        s4.addSink(<span class="keyword">new</span> MysqlSink(parameterTool))</span><br><span class="line">                .setParallelism(parameterTool.getInt(<span class="string">"mysql.sink.parallelism"</span>, <span class="number">1</span>))</span><br><span class="line">                .name(<span class="string">"MysqlSink"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (parameterTool.getBoolean(<span class="string">"app.handler.print.console"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">            s0.print(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从上面的整体中，我们这里先看到设置<code>watermark</code>的逻辑，这个<code>watermark</code>决定了我们的flink的数据的有序性，是一个比较重要的处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 每5s-flink需要获取新的watermark</span></span><br><span class="line">s0.getExecutionConfig().setAutoWatermarkInterval(<span class="number">5000L</span>);</span><br><span class="line"></span><br><span class="line">logger.debug(<span class="string">"getAutoWatermarkInterval: &#123;&#125;"</span>, s0.getExecutionConfig().getAutoWatermarkInterval());</span><br><span class="line">ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;Event&gt; s1 = s0.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarksAdapter.Strategy&lt;&gt;(</span><br><span class="line">				<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.of(<span class="number">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"></span><br><span class="line">					<span class="meta">@Override</span></span><br><span class="line">					<span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">						Long ts = event.getLogs().getMtime() * <span class="number">1000L</span>;</span><br><span class="line">						logger.debug(</span><br><span class="line">								<span class="string">"thread-id: &#123;&#125;, eventTime: [&#123;&#125;|&#123;&#125;], watermark: [&#123;&#125;|&#123;&#125;]"</span>,</span><br><span class="line">								Thread.currentThread().getId(),</span><br><span class="line">								ts,</span><br><span class="line">								sdf.format(ts),</span><br><span class="line">								<span class="keyword">this</span>.getCurrentWatermark().getTimestamp(),</span><br><span class="line">								sdf.format(<span class="keyword">this</span>.getCurrentWatermark().getTimestamp())</span><br><span class="line">						);</span><br><span class="line"></span><br><span class="line">						<span class="keyword">return</span> ts;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">		)</span><br><span class="line">				<span class="comment">// 尽可能和窗口大小保持一致，所以如果其中一个并行度出现问题的情况下</span></span><br><span class="line">				<span class="comment">// 最大的延迟计算结果是一个窗口大小的时间</span></span><br><span class="line">				.withIdleness(Duration.ofMinutes(<span class="number">1L</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>我们这里通过<code>AssignerWithPeriodicWatermarksAdapter</code>设置一个<code>watermark</code>生成的策略。</p>
<p>当数据到来的时候，允许<code>1秒延迟</code>的情况下，解析数据的<code>事件时间(event-time)</code>作为我们的<code>watermark</code>，这里需要注意的是，这里从event-time提取的时间的单位需要是<code>毫秒</code>级别。</p>
<p>再通过<code>.withIdleness</code>，进行当某个窗口下<code>idle</code>了，那么也会刷新<code>watermark</code>。这个知识点，在kafka中是一个很重要的逻辑，由于flink在kafka的topic在多partition下，在partition的数据<code>watermark</code>对齐的情况，才会进行，所以为了防止，由于防止kafka的partition的数据倾斜对我们造成业务逻辑一直无法更新watermark的问题。这个十分必要。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">WindowedStream&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt; s2 = s1.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;&gt;() &#123;</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> Tuple5&lt;Integer, String, String, Integer, String&gt; <span class="title">getKey</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> Tuple5.of(</span><br><span class="line">				event.getLogs().getRelatedAppId(),</span><br><span class="line">				event.getLogs().getChildApp(),</span><br><span class="line">				event.getLogs().getSummary(),</span><br><span class="line">				event.getLogs().getLevel(),</span><br><span class="line">				event.getLogs().getIp()</span><br><span class="line">		);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;)</span><br><span class="line">		.window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1L</span>)));</span><br></pre></td></tr></table></figure>

<p>对于<code>windowstream</code>，主要是定义<code>窗口的时间大小</code>， <code>窗口数据的唯一主键</code>。</p>
<p>在这里，由于我的需求是每1分钟统计一次，所以这里可以看到我的窗口是基于<code>EventTime（事件时间）</code>的窗口，并且大小范围为<code>1分钟</code>。而数据的唯一主键则是通过<code>getKet(Event event)</code>方法来处理。通过flink内置的便捷的<code>Tuple5</code>这个类来处理的原因是因为我这里有5个元素组成的key。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; s3 = s2.apply(<span class="keyword">new</span> WindowFunction&lt;Event, Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple5&lt;Integer, String, String, Integer, String&gt; key, TimeWindow timeWindow, Iterable&lt;Event&gt; iterable, Collector&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (Event event : iterable) &#123;</span><br><span class="line">                    sum++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.debug(<span class="string">"聚合窗口key: &#123;&#125;, 窗口中的数量:&#123;&#125;, 此时的窗口范围是[&#123;&#125;,&#123;&#125;)"</span>, key, sum, sdf.format(timeWindow.getStart()), sdf.format(timeWindow.getEnd()));</span><br><span class="line">                collector.collect(Tuple3.of(key, iterable.iterator().next(), sum));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure>

<p>接下来就是<code>聚合(统计)</code>的逻辑了，当<code>window-trigger-condition</code>满足条件之后，就会把当前窗口内的所有数据推到下一个<code>算子</code>，在这个<code>算子</code>的<code>apply()</code>中，我们可以看到我们只是简单的做了一个数据统计，也就是<code>sum++</code>，经过这一操作之后，经过<code>collector</code>对进行进行<code>收集</code>，准备用于下一个<code>算子</code>中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;MysqlItem&gt; s4 = s3.map(e -&gt; &#123;</span><br><span class="line">                    HashMap&lt;String, Object&gt; kv = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                    kv.put(<span class="string">"related_app_id"</span>, e.f1.getLogs().getRelatedAppId());</span><br><span class="line">                    kv.put(<span class="string">"child_app"</span>, e.f1.getLogs().getChildApp());</span><br><span class="line">                    kv.put(<span class="string">"summary"</span>, e.f1.getLogs().getSummary());</span><br><span class="line">                    kv.put(<span class="string">"level"</span>, e.f1.getLogs().getLevel());</span><br><span class="line">                    kv.put(<span class="string">"ip"</span>, e.f1.getLogs().getIp());</span><br><span class="line"></span><br><span class="line">                    kv.put(<span class="string">"mtime"</span>, e.f1.getLogs().getMtime());</span><br><span class="line">                    kv.put(<span class="string">"mdate"</span>, Util.timeStamp2Date(Integer.toString(e.f1.getLogs().getMtime()), <span class="string">"yyyy-MM-dd"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 来自聚合窗口统计的结果</span></span><br><span class="line">                    kv.put(<span class="string">"cnt"</span>, e.f2);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> MysqlItem.builder()</span><br><span class="line">                            .database(sinkDatabase)</span><br><span class="line">                            .table(sinkTable)</span><br><span class="line">                            .kv(kv)</span><br><span class="line">                            .build();</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(MysqlItem<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">s4.addSink(<span class="keyword">new</span> MysqlSink(parameterTool))</span><br><span class="line">		.setParallelism(parameterTool.getInt(<span class="string">"mysql.sink.parallelism"</span>, <span class="number">1</span>))</span><br><span class="line">		.name(<span class="string">"MysqlSink"</span>);</span><br></pre></td></tr></table></figure>


<p>在这个前面到算子中，我们拿到了一些我们所期待到数据了，接下来就是把数据转换成为我们需要入库的一个结构。通过<code>MysqlItem</code>对象，我们把所有的结构化的对象通过<code>MysqlSink</code>方法进行发送给mysql。<code>mysqlsink</code>是我们自己封的一个<code>sinker</code>，其中的代码实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.sinks;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.Setter;</span><br><span class="line"><span class="keyword">import</span> lombok.experimental.Accessors;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.RichSinkFunction;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Setter</span></span><br><span class="line"><span class="meta">@Accessors</span>(chain = <span class="keyword">true</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MysqlSink</span> <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>&lt;<span class="title">MysqlItem</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(MysqlSink<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    ParameterTool parameterTool;</span><br><span class="line">    <span class="keyword">private</span> Connection connection;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MysqlSink</span><span class="params">(ParameterTool parameterTool)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.parameterTool = parameterTool;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">        <span class="keyword">if</span> (connection == <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection = <span class="keyword">this</span>.getConnection();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * todo: 再考虑一下如果插入失败的话是否需要重试之类的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> item</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(MysqlItem item, Context context)</span> </span>&#123;</span><br><span class="line">        logger.debug(<span class="string">"mysql-item: &#123;&#125;"</span>, item);</span><br><span class="line">        MysqlItem.Sql sqlInfo = item.toInsertIgnoreSql();</span><br><span class="line">        String sql = sqlInfo.getPreSql();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            PreparedStatement ps = <span class="keyword">this</span>.connection.prepareStatement(sql);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= sqlInfo.getValues().size(); i++) &#123;</span><br><span class="line">                ps.setObject(i, sqlInfo.getValues().get(i-<span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            logger.debug(ps.toString());</span><br><span class="line">            ps.execute();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            logger.error(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Connection <span class="title">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> ClassNotFoundException, SQLException </span>&#123;</span><br><span class="line">        Class.forName(<span class="string">"com.mysql.cj.jdbc.Driver"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> DriverManager.getConnection(</span><br><span class="line">                String.format(</span><br><span class="line">                        <span class="string">"jdbc:mysql://%s:%s/?useUnicode=true&amp;characterEncoding=%s&amp;useSSL=false&amp;autoReconnect=true"</span>,</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.host"</span>),</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.port"</span>),</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.characterEncoding"</span>, StandardCharsets.UTF_8.toString())</span><br><span class="line">                ),</span><br><span class="line">                <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.user"</span>),</span><br><span class="line">                <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.password"</span>)</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>到此，一个基于<code>datastream-api</code>的job，就完成了。</p>
<p>但是由于这是<code>java技术栈</code>，对于不是<code>java技术栈</code>的团队而言，这是一件比较麻烦的事情。就算是<code>java技术栈</code>，也需要去属于了解flink的原理，然后去编写对应的flink代码，这对于不熟悉<code>datastream-api</code>的小伙伴来说，也是一种头痛的事情。</p>
<p>所以对于这个问题，我们考虑使用上层一些的api，也就是<code>table-api</code>和<code>sql-api</code>。</p>
<p>但是由于此类api还是需要熟悉api的细节，所以我们看到了flink提供了一个叫<code>sql-client</code>的东西。但是由于<code>sql-client</code>的不稳定性（某些版本下存在比较严重的bug），且某些需求无法满足我们，为了灵活和可控性，我们最终解决了自行开发<code>flink-sql-client</code>。</p>
<h2 id="基于自研sql-client的flink开发"><a href="#基于自研sql-client的flink开发" class="headerlink" title="基于自研sql-client的flink开发"></a>基于自研<code>sql-client</code>的flink开发</h2><p>具体的实现方式在 <a href="https://github.com/whiteCcinn/flink-sql-submit" target="_blank" rel="noopener">flink-sql-submit</a></p>
<p>实现原理其实也不复杂，其实就是通过一个flink项目，封装成为一个类似cmd的命令，然后通过此方式来提交我们的<code>sql或者sql文件</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">src/main/java/</span><br><span class="line">├── deps</span><br><span class="line">│   └── util</span><br><span class="line">│       ├── ParameterToolEnvironmentUtils.java</span><br><span class="line">│       ├── SqlCommandParser.java</span><br><span class="line">│       └── Util.java</span><br><span class="line">└── org</span><br><span class="line">    └── client</span><br><span class="line">        └── flink</span><br><span class="line">            ├── Bootstrap.java</span><br><span class="line">            ├── SqlSubmit.java</span><br><span class="line">            ├── cmds</span><br><span class="line">            │   ├── AbstractCommand.java</span><br><span class="line">            │   ├── HelpCommand.java</span><br><span class="line">            │   ├── HiveCatalogCommand.java</span><br><span class="line">            │   ├── ICommand.java</span><br><span class="line">            │   ├── JobCommand.java</span><br><span class="line">            │   └── SqlParserCommand.java</span><br><span class="line">            ├── enums</span><br><span class="line">            │   └── PlanType.java</span><br><span class="line">            ├── internals</span><br><span class="line">            └── udfs</span><br></pre></td></tr></table></figure>

<p>我们可以看到，整个项目只有少量文件。提供了几个命令：</p>
<ul>
<li>help 帮助命令</li>
<li>hivecatalog 管理<ul>
<li>增</li>
<li>删</li>
<li>查</li>
</ul>
</li>
<li>job 提交任务<ul>
<li>sql</li>
<li>sql-file</li>
</ul>
</li>
<li>sql-parser 调试解析sql</li>
</ul>
<p>我们以一个<code>sql-file</code>为例子，其他大家可以在github上查看源码。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 以":"为分隔符，分别代表：catalog_type, hive_conf_path, catalog_name</span></span><br><span class="line"><span class="comment">-- "-" 代表使用默认值</span></span><br><span class="line">CATALOG_INFO = hive:/opt/hadoopclient/Hive/config/:-;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> mstream_alarm <span class="keyword">COMMENT</span> <span class="string">'告警系统流计算'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">USE</span> mstream_alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'pipeline.name'</span> = <span class="string">'每1分钟基础服务告警'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.emit.early-fire.enabled'</span> = <span class="string">'true'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.emit.early-fire.delay'</span> = <span class="string">'10s'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.local.time.zone'</span> = <span class="string">'Asia/Shanghai'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.sink.not-null-enforcer'</span> = <span class="string">'drop'</span>;</span><br><span class="line"><span class="comment">-- checkpoint配置</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.mode'</span> = <span class="string">'EXACTLY_ONCE'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.interval'</span> = <span class="string">'2min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.timeout'</span> = <span class="string">'1min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.prefer-checkpoint-for-recovery'</span> = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.externalized-checkpoint-retention'</span> = <span class="string">'RETAIN_ON_CANCELLATION'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.state.backend.fs.checkpointdir'</span> = <span class="string">'hdfs:///flink/checkpoints/&#123;db&#125;/&#123;pipeline.name&#125;'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.execution.savepoint.dir'</span> = <span class="string">'hdfs:///flink/savepoints/&#123;db&#125;/&#123;pipeline.name&#125;'</span>;</span><br><span class="line"><span class="comment">-- 重启策略</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy'</span> = <span class="string">'failure-rate'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.delay'</span> = <span class="string">'10s'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.failure-rate-interval'</span> = <span class="string">'5min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.max-failures-per-interval'</span> = <span class="string">'10'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> app_error_To_t_log_app_error_alarm_164 (</span><br><span class="line">    headers <span class="keyword">ROW</span>&lt;<span class="string">`app_id`</span> <span class="built_in">int</span>,<span class="string">`log_name`</span> <span class="keyword">string</span>&gt;,</span><br><span class="line">    <span class="keyword">logs</span> <span class="keyword">ROW</span>&lt;<span class="string">`related_app_id`</span> <span class="built_in">int</span>, <span class="string">`child_app`</span> <span class="built_in">varchar</span>(<span class="number">200</span>), <span class="string">`summary`</span> <span class="keyword">string</span>,<span class="string">`level`</span> <span class="built_in">int</span>,<span class="string">`ip`</span> <span class="built_in">varchar</span>(<span class="number">200</span>),<span class="string">`detail`</span> <span class="built_in">varchar</span>(<span class="number">100</span>), <span class="string">`mtime`</span> <span class="built_in">int</span>&gt;,</span><br><span class="line">    etime <span class="keyword">as</span> TO_TIMESTAMP(FROM_UNIXTIME(logs.<span class="string">`mtime`</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">for</span> etime <span class="keyword">AS</span> etime <span class="comment">-- defines watermark on ts column, marks ts as event-time attribute</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>,</span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'mfeilog_dsp_10008_app_error'</span>,</span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'127.0.0.1:9092'</span>,</span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'app_error_to_t_log_app_error_alarm_164'</span>,</span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'json'</span>,</span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'latest-offset'</span>,</span><br><span class="line">    <span class="string">'json.fail-on-missing-field'</span> = <span class="string">'false'</span>,</span><br><span class="line">    <span class="string">'json.ignore-parse-errors'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`t_log_app_error_alarm_164`</span> (</span><br><span class="line">  <span class="string">`related_app_id`</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="string">`child_app`</span> <span class="built_in">varchar</span>(<span class="number">200</span>),</span><br><span class="line">  <span class="string">`summary`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`level`</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="string">`ip`</span> <span class="built_in">varchar</span>(<span class="number">200</span>) ,</span><br><span class="line">  <span class="string">`cnt`</span> <span class="built_in">varchar</span>(<span class="number">200</span>) <span class="keyword">COMMENT</span> <span class="string">'calculate the detail of count()'</span>,</span><br><span class="line">  <span class="string">`mdate`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`mtime`</span> <span class="built_in">int</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`related_app_id`</span>,<span class="string">`child_app`</span>,<span class="string">`summary`</span>,<span class="string">`level`</span>,<span class="string">`ip`</span>) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'jdbc'</span>,</span><br><span class="line">   <span class="string">'url'</span> = <span class="string">'jdbc:mysql://127.0.0.1:60701/db_app_log_alarm?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true'</span>,</span><br><span class="line">   <span class="string">'driver'</span> = <span class="string">'com.mysql.cj.jdbc.Driver'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'t_log_app_error_alarm_164'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'flink_mstream_alarm'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'xxxx'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_log_app_error_alarm_164 (</span><br><span class="line">    <span class="keyword">select</span> t1.<span class="string">`related_app_id`</span>,t1.<span class="string">`child_app`</span>,t1.<span class="string">`summary`</span>,t1.<span class="string">`level`</span>,t1.<span class="string">`ip`</span>,<span class="keyword">cast</span>(t1.<span class="string">`cnt`</span> <span class="keyword">as</span> <span class="built_in">VARCHAR</span>(<span class="number">200</span>)) <span class="keyword">as</span> <span class="string">`cnt`</span>,t1.<span class="string">`mdate`</span>,<span class="keyword">cast</span> (t1.<span class="string">`mtime`</span> <span class="keyword">as</span> <span class="built_in">INT</span>)  <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            logs.<span class="string">`related_app_id`</span> <span class="keyword">as</span> <span class="string">`related_app_id`</span>,</span><br><span class="line">            logs.<span class="string">`child_app`</span> <span class="keyword">as</span> <span class="string">`child_app`</span>,</span><br><span class="line">            logs.<span class="string">`summary`</span> <span class="keyword">as</span> <span class="string">`summary`</span>,</span><br><span class="line">            logs.<span class="string">`level`</span> <span class="keyword">as</span> <span class="string">`level`</span>,</span><br><span class="line">            logs.<span class="string">`ip`</span> <span class="keyword">as</span> <span class="string">`ip`</span>,</span><br><span class="line">            <span class="keyword">DATE_FORMAT</span>(TUMBLE_START(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>), <span class="string">'yyyy-MM-dd'</span>) <span class="keyword">as</span> <span class="string">`mdate`</span>,</span><br><span class="line">            <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">DATE_FORMAT</span>(TUMBLE_START(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>), <span class="string">'yyyy-MM-dd HH:mm:ss'</span>)) <span class="keyword">as</span> <span class="string">`mtime`</span>,</span><br><span class="line">            <span class="keyword">COUNT</span>(logs.<span class="string">`detail`</span>) <span class="keyword">as</span> <span class="string">`cnt`</span></span><br><span class="line">        <span class="keyword">FROM</span> app_error_To_t_log_app_error_alarm_164</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> logs.<span class="string">`related_app_id`</span>, logs.<span class="string">`child_app`</span>,logs.<span class="string">`summary`</span>,logs.<span class="string">`level`</span>,logs.<span class="string">`ip`</span>,TUMBLE(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>)</span><br><span class="line">    ) t1</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>我们可以看到这个<code>sql-file</code>，支持了一些<code>关键字</code>，这些关键字被开发在<code>client</code>当中了，所以可以被正常解析到。</p>
<p>通过解析到关键字，再调用对应的API，我们就可以设置对应的行为了。</p>
<p>我们可以看到我们从繁杂的<code>datastreamapi</code>中，已经把剥离了出来，通过sql这种DSL的方式，让不同语言技术栈的同事都可以定制自己的job。</p>
<p>并且支持了自定义重启策略，保证每一个算子在异常或者正常的情况下，都可以从正确的数据中进行恢复重启。</p>
<p>这一套sql编写下来，做的事情和我们上面的<code>datastream</code>做的事情是一样的，但是却无需了解太多其中的细节。</p>
<h4 id="UDF的运用"><a href="#UDF的运用" class="headerlink" title="UDF的运用"></a>UDF的运用</h4><p>例如我们需要ip转地址字符串，这个时候，我们就需要udf来协助我们完成这件事。</p>
<p>client项目可以内置一些我们所需要的UDF，然后连同job一起生效。</p>
<p>例如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@127.0,0.1_A ~]# flink run -yid `cat /data/flink-stream/mstream/mstream_xx/yid` /data/flink-stream/flink-sql-submit-1.0-SNAPSHOT.jar job --sql "CATALOG_INFO = hive:/opt/hadoopclient/Hive/config/:-;USE mstream_alarm;SELECT ip2location('219.135.155.76');"</span><br><span class="line"> Interface ana-group-1byez.dad44e53-24e6-41be-bfd5-a4055f4c6604.com:32263 of application 'application_1641337362340_6699'.</span><br><span class="line">Job has been submitted with JobID 824af5a31aba88db6e0137f5e834f26b</span><br><span class="line">+----+--------------------------------+</span><br><span class="line">| op |                         EXPR$0 |</span><br><span class="line">+----+--------------------------------+</span><br><span class="line">| +I |                 中国,广东,广州 |</span><br><span class="line">+----+--------------------------------+</span><br></pre></td></tr></table></figure>

<p>我们可以看到，通过<code>ip2localtion()</code>，我们完成了一个udf，并且可以实现在sql的模式上。用过ip地址转为为了地址。</p>
<h2 id="落地实战"><a href="#落地实战" class="headerlink" title="落地实战"></a>落地实战</h2><p>由于资源的有限，我们在flink的架构上，采用的是每个项目对应一个<code>application</code>的方法，每个<code>application通过yarn来分配来分配资源容器</code>，然后再通过<code>yarn-session</code>(非<code>per on job</code>)的方式来管理我们的flink应用。</p>
<h3 id="申请资源应用"><a href="#申请资源应用" class="headerlink" title="申请资源应用"></a>申请资源应用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-session.sh -jm 1024 -tm 1024 -s 16 -nm '告警流计算应用' -yd</span><br></pre></td></tr></table></figure>

<p><img src="/images/FLINK/application.png" alt="application"></p>
<h3 id="client-例子"><a href="#client-例子" class="headerlink" title="client 例子"></a>client 例子</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">help</span></span></span><br><span class="line">root@41c5967b5948:/www# flink run target/mc-flink-sql-submit-1.0-SNAPSHOT.jar help</span><br><span class="line">帮助命令</span><br><span class="line"></span><br><span class="line">Usage of "flink run &lt;.jar&gt; help [options]"</span><br><span class="line"></span><br><span class="line">Available Commands</span><br><span class="line">   job          提交job作业</span><br><span class="line">   sql-parser   解析sql文件</span><br><span class="line">   help         帮助命令</span><br><span class="line">   hive-catalog hive-catalog的相关</span><br><span class="line"></span><br><span class="line">Global Options:</span><br><span class="line">   --app.force.remote bool</span><br><span class="line">       是否启动远端环境变量: false</span><br><span class="line">   --app.config.debug bool</span><br><span class="line">       是否打印用户参数: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> job</span></span><br><span class="line">root@41c5967b5948:/www# flink run target/mc-flink-sql-submit-1.0-SNAPSHOT.jar job help</span><br><span class="line">提交job</span><br><span class="line"></span><br><span class="line">Usage of "flink run &lt;.jar&gt; job [options]"</span><br><span class="line">   --sql string</span><br><span class="line">       执行的sql (*)</span><br><span class="line">   --plan string</span><br><span class="line">       选择执行计划器:</span><br><span class="line">           flink-streaming</span><br><span class="line">           flink-batch</span><br><span class="line">           blink-streaming</span><br><span class="line">           flink-batch</span><br><span class="line"></span><br><span class="line">Global Options:</span><br><span class="line">   --app.force.remote bool</span><br><span class="line">       是否启动远端环境变量: false</span><br><span class="line">   --app.config.debug bool</span><br><span class="line">       是否打印用户参数: false</span><br></pre></td></tr></table></figure>

<h3 id="flink-stream-sql-mctl-用法"><a href="#flink-stream-sql-mctl-用法" class="headerlink" title="flink-stream-sql-mctl 用法"></a>flink-stream-sql-mctl 用法</h3><p>这是一个集成脚本，所以存在约定的规则和部署的架构约束。</p>
<p>这便于我们管理所有的applition和flink种的所有flink-job。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">flink-sql-submit git:(master) ✗ ./flink-stream-sql-mctl.sh</span><br><span class="line"></span><br><span class="line">  flink-stream-sql-mctl.sh [OPTION] &lt;COMMAND&gt;</span><br><span class="line"></span><br><span class="line">  Flink流计算SQL-Client的执行脚本</span><br><span class="line"></span><br><span class="line">  Command:</span><br><span class="line">    run          [FILE]            运行</span><br><span class="line">    stop         [FILE]            停止</span><br><span class="line">    list         [FILE]            列出FILE所在yid下的所有job任务列表</span><br><span class="line">    drop_table   [FILE]            删除所有表</span><br><span class="line">    rebuild_run  [FILE]            删除所有表，然后重跑(继承savepoint）</span><br><span class="line"></span><br><span class="line">  Command-Common-Options:</span><br><span class="line">    -c, --clientpath  [LEVEL]    flink-sql-submit.jar路径  (Default is '/data/tmp/mc-flink-sql-submit-1.0-SNAPSHOT.jar')</span><br><span class="line">    -f   是否强制运行，忽略以往savepoint</span><br><span class="line"></span><br><span class="line">  Common-Options:</span><br><span class="line">    -h, --help              Display this help and exit</span><br><span class="line">    --loglevel [LEVEL]      One of: FATAL, ERROR, WARN, INFO, NOTICE, DEBUG, ALL, OFF</span><br><span class="line">                            (Default is 'ERROR')</span><br><span class="line">    --logfile [FILE]        Full PATH to logfile.  (Default is '/Users/caiwenhui/logs/flink-stream-sql-mctl.sh.log')</span><br><span class="line">    -n, --dryrun            Non-destructive. Makes no permanent changes.</span><br><span class="line">    -q, --quiet             Quiet (no output)</span><br><span class="line">    -v, --verbose           Output more information. (Items echoed to 'verbose')</span><br><span class="line">    --force                 Skip all user interaction.  Implied 'Yes' to all actions.</span><br></pre></td></tr></table></figure>

<p>约定规则：</p>
<ul>
<li>模型所在父目录的至少有一个yid文件（取最近的一个父节点的yid）对应所在的应用id</li>
<li>默认情况下，模型启动的时候会取最近一次savepoint的数据进行恢复，如果不存在，则直接启动</li>
</ul>
<h3 id="停止所有模型"><a href="#停止所有模型" class="headerlink" title="停止所有模型"></a>停止所有模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl stop $i;done</span><br></pre></td></tr></table></figure>

<h3 id="启动所有模型"><a href="#启动所有模型" class="headerlink" title="启动所有模型"></a>启动所有模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl run $i;done</span><br></pre></td></tr></table></figure>

<h3 id="删除所有表"><a href="#删除所有表" class="headerlink" title="删除所有表"></a>删除所有表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl drop_table $i;done</span><br></pre></td></tr></table></figure>

<h3 id="相关的一些落地后截图信息"><a href="#相关的一些落地后截图信息" class="headerlink" title="相关的一些落地后截图信息"></a>相关的一些落地后截图信息</h3><p><img src="/images/FLINK/server.png" alt="server"></p>
<p><img src="/images/FLINK/detail-0.png" alt="detail-0"></p>
<p><img src="/images/FLINK/detail-1.png" alt="detail-1"></p>
<p><img src="/images/FLINK/detail-2.png" alt="detail-2"></p>
<p><img src="/images/FLINK/detail-3.png" alt="detail-3"></p>
<p>到此为止，我们的flink相关的流计算应用，从0到1的过程暂时画上一个里程碑。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/大数据/">大数据</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/flink/">flink</a>
    </span>
    

    </div>

    
  </div>
</article>

  






    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2025 白菜(whiteCcinn)
    
  </p>
</footer>
    
  </div>
</div>
</body>
</html>